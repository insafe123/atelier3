{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO7OvR7l055e0aQ2/rcKkK2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"bEU57-WTukMI"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"ZC6P-_a5pCW9","executionInfo":{"status":"ok","timestamp":1669058557531,"user_tz":-60,"elapsed":2917,"user":{"displayName":"Insafe MECHHEDAN","userId":"11716799724651238097"}}},"outputs":[],"source":["#Setup\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras"]},{"cell_type":"code","source":["#Download the Newsgroup20 data\n","data_path = keras.utils.get_file(\n","    \"news20.tar.gz\",\n","    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",\n","    untar=True,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dZurC3h0pIrQ","executionInfo":{"status":"ok","timestamp":1669058604003,"user_tz":-60,"elapsed":36713,"user":{"displayName":"Insafe MECHHEDAN","userId":"11716799724651238097"}},"outputId":"32611270-6aa6-4197-aabe-e316aba682d1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\n","17329808/17329808 [==============================] - 28s 2us/step\n"]}]},{"cell_type":"code","source":["#Let's take a look at the data\n","import os\n","import pathlib\n","\n","data_dir = pathlib.Path(data_path).parent / \"20_newsgroup\"\n","dirnames = os.listdir(data_dir)\n","print(\"Number of directories:\", len(dirnames))\n","print(\"Directory names:\", dirnames)\n","\n","fnames = os.listdir(data_dir / \"comp.graphics\")\n","print(\"Number of files in comp.graphics:\", len(fnames))\n","print(\"Some example filenames:\", fnames[:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-r0P70FJpNN7","executionInfo":{"status":"ok","timestamp":1669058613244,"user_tz":-60,"elapsed":434,"user":{"displayName":"Insafe MECHHEDAN","userId":"11716799724651238097"}},"outputId":"6593a2ea-6fba-4a96-9e9e-c21d3c01afaa"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of directories: 20\n","Directory names: ['rec.sport.hockey', 'comp.sys.mac.hardware', 'sci.med', 'misc.forsale', 'rec.autos', 'comp.windows.x', 'rec.motorcycles', 'talk.politics.guns', 'comp.graphics', 'rec.sport.baseball', 'comp.sys.ibm.pc.hardware', 'sci.space', 'comp.os.ms-windows.misc', 'soc.religion.christian', 'talk.politics.misc', 'alt.atheism', 'sci.crypt', 'talk.religion.misc', 'talk.politics.mideast', 'sci.electronics']\n","Number of files in comp.graphics: 1000\n","Some example filenames: ['38806', '39617', '38405', '38634', '38688']\n"]}]},{"cell_type":"code","source":["#Here's a example of what one file contains:\n","print(open(data_dir / \"comp.graphics\" / \"38987\").read())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZK994C4TpSsB","executionInfo":{"status":"ok","timestamp":1669058618082,"user_tz":-60,"elapsed":435,"user":{"displayName":"Insafe MECHHEDAN","userId":"11716799724651238097"}},"outputId":"fc0b54b8-e8d2-4966-e2ee-8dbdad3e4e3d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Newsgroups: comp.graphics\n","Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!noc.near.net!howland.reston.ans.net!agate!dog.ee.lbl.gov!network.ucsd.edu!usc!rpi!nason110.its.rpi.edu!mabusj\n","From: mabusj@nason110.its.rpi.edu (Jasen M. Mabus)\n","Subject: Looking for Brain in CAD\n","Message-ID: <c285m+p@rpi.edu>\n","Nntp-Posting-Host: nason110.its.rpi.edu\n","Reply-To: mabusj@rpi.edu\n","Organization: Rensselaer Polytechnic Institute, Troy, NY.\n","Date: Thu, 29 Apr 1993 23:27:20 GMT\n","Lines: 7\n","\n","Jasen Mabus\n","RPI student\n","\n","\tI am looking for a hman brain in any CAD (.dxf,.cad,.iges,.cgm,etc.) or picture (.gif,.jpg,.ras,etc.) format for an animation demonstration. If any has or knows of a location please reply by e-mail to mabusj@rpi.edu.\n","\n","Thank you in advance,\n","Jasen Mabus  \n","\n"]}]},{"cell_type":"code","source":["#As you can see, there are header lines that are leaking the file's category, either explicitly (the first line is literally the category name), or implicitly, e.g. via the Organization filed. Let's get rid of the headers:\n","samples = []\n","labels = []\n","class_names = []\n","class_index = 0\n","for dirname in sorted(os.listdir(data_dir)):\n","    class_names.append(dirname)\n","    dirpath = data_dir / dirname\n","    fnames = os.listdir(dirpath)\n","    print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\n","    for fname in fnames:\n","        fpath = dirpath / fname\n","        f = open(fpath, encoding=\"latin-1\")\n","        content = f.read()\n","        lines = content.split(\"\\n\")\n","        lines = lines[10:]\n","        content = \"\\n\".join(lines)\n","        samples.append(content)\n","        labels.append(class_index)\n","    class_index += 1\n","\n","print(\"Classes:\", class_names)\n","print(\"Number of samples:\", len(samples))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vhlKT5xepWml","executionInfo":{"status":"ok","timestamp":1669058648496,"user_tz":-60,"elapsed":2093,"user":{"displayName":"Insafe MECHHEDAN","userId":"11716799724651238097"}},"outputId":"d77044c7-43be-45b9-9f44-aa26590bb699"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing alt.atheism, 1000 files found\n","Processing comp.graphics, 1000 files found\n","Processing comp.os.ms-windows.misc, 1000 files found\n","Processing comp.sys.ibm.pc.hardware, 1000 files found\n","Processing comp.sys.mac.hardware, 1000 files found\n","Processing comp.windows.x, 1000 files found\n","Processing misc.forsale, 1000 files found\n","Processing rec.autos, 1000 files found\n","Processing rec.motorcycles, 1000 files found\n","Processing rec.sport.baseball, 1000 files found\n","Processing rec.sport.hockey, 1000 files found\n","Processing sci.crypt, 1000 files found\n","Processing sci.electronics, 1000 files found\n","Processing sci.med, 1000 files found\n","Processing sci.space, 1000 files found\n","Processing soc.religion.christian, 997 files found\n","Processing talk.politics.guns, 1000 files found\n","Processing talk.politics.mideast, 1000 files found\n","Processing talk.politics.misc, 1000 files found\n","Processing talk.religion.misc, 1000 files found\n","Classes: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n","Number of samples: 19997\n"]}]},{"cell_type":"code","source":["# Shuffle the data\n","seed = 1337\n","rng = np.random.RandomState(seed)\n","rng.shuffle(samples)\n","rng = np.random.RandomState(seed)\n","rng.shuffle(labels)\n","\n","# Extract a training & validation split\n","validation_split = 0.2\n","num_validation_samples = int(validation_split * len(samples))\n","train_samples = samples[:-num_validation_samples]\n","val_samples = samples[-num_validation_samples:]\n","train_labels = labels[:-num_validation_samples]\n","val_labels = labels[-num_validation_samples:]"],"metadata":{"id":"O5FghcFtphSV","executionInfo":{"status":"ok","timestamp":1669058669205,"user_tz":-60,"elapsed":463,"user":{"displayName":"Insafe MECHHEDAN","userId":"11716799724651238097"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#Create a vocabulary index\n","from tensorflow.keras.layers import TextVectorization\n","\n","vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n","text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n","vectorizer.adapt(text_ds)"],"metadata":{"id":"RIHouT8qpl65","executionInfo":{"status":"ok","timestamp":1669058691097,"user_tz":-60,"elapsed":4415,"user":{"displayName":"Insafe MECHHEDAN","userId":"11716799724651238097"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#You can retrieve the computed vocabulary used via vectorizer.get_vocabulary(). Let's print the top 5 words:\n","vectorizer.get_vocabulary()[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3A9lmLgFpp3h","executionInfo":{"status":"ok","timestamp":1669058705336,"user_tz":-60,"elapsed":607,"user":{"displayName":"Insafe MECHHEDAN","userId":"11716799724651238097"}},"outputId":"3aa770fe-ed8b-4622-eba0-9a3e786ba3f5"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['', '[UNK]', 'the', 'to', 'of']"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["#Let's vectorize a test sentence:\n","output = vectorizer([[\"the cat sat on the mat\"]])\n","output.numpy()[0, :6]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rzZFWBS4pugY","executionInfo":{"status":"ok","timestamp":1669058722632,"user_tz":-60,"elapsed":7,"user":{"displayName":"Insafe MECHHEDAN","userId":"11716799724651238097"}},"outputId":"cb978ebe-1a76-4343-bc4a-d1a34a8afd37"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([   2, 3444, 1688,   15,    2, 5856])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["#Here's a dict mapping words to their indices:\n","voc = vectorizer.get_vocabulary()\n","word_index = dict(zip(voc, range(len(voc))))"],"metadata":{"id":"oJPY_4-9px7F","executionInfo":{"status":"ok","timestamp":1669058735820,"user_tz":-60,"elapsed":4,"user":{"displayName":"Insafe MECHHEDAN","userId":"11716799724651238097"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#As you can see, we obtain the same encoding as above for our test sentence:\n","test = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n","[word_index[w] for w in test]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SyD_80okp1zJ","executionInfo":{"status":"ok","timestamp":1669058751656,"user_tz":-60,"elapsed":8,"user":{"displayName":"Insafe MECHHEDAN","userId":"11716799724651238097"}},"outputId":"e6a219a4-54ad-410a-aac3-22d091efb780"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[2, 3444, 1688, 15, 2, 5856]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["#Load pre-trained word embeddings\n","!wget http://nlp.stanford.edu/data/glove.6B.zip\n","!unzip -q glove.6B.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YL-aReN9p8mT","executionInfo":{"status":"ok","timestamp":1669058965137,"user_tz":-60,"elapsed":186175,"user":{"displayName":"Insafe MECHHEDAN","userId":"11716799724651238097"}},"outputId":"8abeefed-57aa-4852-af9f-379789fecb8e"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-11-21 19:26:17--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2022-11-21 19:26:17--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n","--2022-11-21 19:26:18--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: ‘glove.6B.zip’\n","\n","glove.6B.zip        100%[===================>] 822.24M  5.10MB/s    in 2m 40s  \n","\n","2022-11-21 19:28:58 (5.14 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n","\n"]}]},{"cell_type":"code","source":["!ls\n","!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZUeHeI9UsGdL","executionInfo":{"status":"ok","timestamp":1669059348271,"user_tz":-60,"elapsed":477,"user":{"displayName":"Insafe MECHHEDAN","userId":"11716799724651238097"}},"outputId":"fd63f8ba-d5eb-4ab6-e27f-ff59b4415fce"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\n","glove.6B.200d.txt  glove.6B.50d.txt   sample_data\n","/content\n"]}]},{"cell_type":"code","source":["#Let's make a dict mapping words (strings) to their NumPy vector representation:\n","path_to_glove_file = os.path.join(\n","    os.path.expanduser(\"~\"), \".keras/datasets/glove.6B.100d.txt\"\n",")\n","\n","embeddings_index = {}\n","with open(path_to_glove_file) as f:\n","    for line in f:\n","        word, coefs = line.split(maxsplit=1)\n","        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n","        embeddings_index[word] = coefs\n","\n","print(\"Found %s word vectors.\" % len(embeddings_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"M0UrsHJIqAmT","executionInfo":{"status":"error","timestamp":1669059525178,"user_tz":-60,"elapsed":420,"user":{"displayName":"Insafe MECHHEDAN","userId":"11716799724651238097"}},"outputId":"9be19b5e-b308-4596-a49d-c96e1dcbcfbf"},"execution_count":21,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-624ece89cc51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0membeddings_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_glove_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxsplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/.keras/datasets/glove.6B.100d.txt'"]}]},{"cell_type":"code","source":["#Now, let's prepare a corresponding embedding matrix that we can use in a Keras Embedding layer. It's a simple NumPy matrix where entry at index i is the pre-trained vector for the word of index i in our vectorizer's vocabulary.\n","num_tokens = len(voc) + 2\n","embedding_dim = 100\n","hits = 0\n","misses = 0\n","\n","# Prepare embedding matrix\n","embedding_matrix = np.zeros((num_tokens, embedding_dim))\n","for word, i in word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        # Words not found in embedding index will be all-zeros.\n","        # This includes the representation for \"padding\" and \"OOV\"\n","        embedding_matrix[i] = embedding_vector\n","        hits += 1\n","    else:\n","        misses += 1\n","print(\"Converted %d words (%d misses)\" % (hits, misses))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EF0eJJ5HqGA9","executionInfo":{"status":"ok","timestamp":1669059533286,"user_tz":-60,"elapsed":439,"user":{"displayName":"Insafe MECHHEDAN","userId":"11716799724651238097"}},"outputId":"614bf97d-7f18-4774-d18f-5c784b1a0be7"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Converted 0 words (20000 misses)\n"]}]},{"cell_type":"code","source":["#Next, we load the pre-trained word embeddings matrix into an Embedding layer.\n","from tensorflow.keras.layers import Embedding\n","\n","embedding_layer = Embedding(\n","    num_tokens,\n","    embedding_dim,\n","    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n","    trainable=False,\n",")"],"metadata":{"id":"xeKHksPHqJ7Z","executionInfo":{"status":"ok","timestamp":1669059538455,"user_tz":-60,"elapsed":498,"user":{"displayName":"Insafe MECHHEDAN","userId":"11716799724651238097"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["#Build the model\n","from tensorflow.keras import layers\n","\n","int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n","embedded_sequences = embedding_layer(int_sequences_input)\n","x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n","x = layers.MaxPooling1D(5)(x)\n","x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n","x = layers.MaxPooling1D(5)(x)\n","x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n","x = layers.GlobalMaxPooling1D()(x)\n","x = layers.Dense(128, activation=\"relu\")(x)\n","x = layers.Dropout(0.5)(x)\n","preds = layers.Dense(len(class_names), activation=\"softmax\")(x)\n","model = keras.Model(int_sequences_input, preds)\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ob0hT72fqQAU","executionInfo":{"status":"ok","timestamp":1669059543464,"user_tz":-60,"elapsed":569,"user":{"displayName":"Insafe MECHHEDAN","userId":"11716799724651238097"}},"outputId":"fd76c3fa-5997-4b4c-963b-57dae73be769"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," embedding (Embedding)       (None, None, 100)         2000200   \n","                                                                 \n"," conv1d (Conv1D)             (None, None, 128)         64128     \n","                                                                 \n"," max_pooling1d (MaxPooling1D  (None, None, 128)        0         \n"," )                                                               \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, None, 128)         82048     \n","                                                                 \n"," max_pooling1d_1 (MaxPooling  (None, None, 128)        0         \n"," 1D)                                                             \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, None, 128)         82048     \n","                                                                 \n"," global_max_pooling1d (Globa  (None, 128)              0         \n"," lMaxPooling1D)                                                  \n","                                                                 \n"," dense (Dense)               (None, 128)               16512     \n","                                                                 \n"," dropout (Dropout)           (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 20)                2580      \n","                                                                 \n","=================================================================\n","Total params: 2,247,516\n","Trainable params: 247,316\n","Non-trainable params: 2,000,200\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["#Train the model\n","x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n","x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n","\n","y_train = np.array(train_labels)\n","y_val = np.array(val_labels)"],"metadata":{"id":"1kv9r9l9qUju","executionInfo":{"status":"ok","timestamp":1669059563949,"user_tz":-60,"elapsed":15216,"user":{"displayName":"Insafe MECHHEDAN","userId":"11716799724651238097"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["#We use categorical crossentropy as our loss since we're doing softmax classification. Moreover, we use sparse_categorical_crossentropy since our labels are integers.\n","model.compile(\n","    loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"]\n",")\n","model.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FTOt-g5QqYSw","executionInfo":{"status":"ok","timestamp":1669060269316,"user_tz":-60,"elapsed":684021,"user":{"displayName":"Insafe MECHHEDAN","userId":"11716799724651238097"}},"outputId":"8121e804-0844-4923-cfd7-8f1502c9bdc3"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","125/125 [==============================] - 37s 281ms/step - loss: 2.9959 - acc: 0.0446 - val_loss: 2.9959 - val_acc: 0.0475\n","Epoch 2/20\n","125/125 [==============================] - 34s 272ms/step - loss: 2.9959 - acc: 0.0497 - val_loss: 2.9960 - val_acc: 0.0480\n","Epoch 3/20\n","125/125 [==============================] - 31s 250ms/step - loss: 2.9959 - acc: 0.0456 - val_loss: 2.9961 - val_acc: 0.0475\n","Epoch 4/20\n","125/125 [==============================] - 33s 263ms/step - loss: 2.9959 - acc: 0.0476 - val_loss: 2.9961 - val_acc: 0.0470\n","Epoch 5/20\n","125/125 [==============================] - 31s 249ms/step - loss: 2.9958 - acc: 0.0481 - val_loss: 2.9962 - val_acc: 0.0470\n","Epoch 6/20\n","125/125 [==============================] - 32s 258ms/step - loss: 2.9959 - acc: 0.0483 - val_loss: 2.9963 - val_acc: 0.0470\n","Epoch 7/20\n","125/125 [==============================] - 32s 259ms/step - loss: 2.9959 - acc: 0.0489 - val_loss: 2.9963 - val_acc: 0.0470\n","Epoch 8/20\n","125/125 [==============================] - 31s 249ms/step - loss: 2.9959 - acc: 0.0489 - val_loss: 2.9963 - val_acc: 0.0475\n","Epoch 9/20\n","125/125 [==============================] - 34s 273ms/step - loss: 2.9958 - acc: 0.0493 - val_loss: 2.9963 - val_acc: 0.0470\n","Epoch 10/20\n","125/125 [==============================] - 31s 249ms/step - loss: 2.9959 - acc: 0.0477 - val_loss: 2.9963 - val_acc: 0.0475\n","Epoch 11/20\n","125/125 [==============================] - 32s 260ms/step - loss: 2.9958 - acc: 0.0483 - val_loss: 2.9963 - val_acc: 0.0475\n","Epoch 12/20\n","125/125 [==============================] - 34s 272ms/step - loss: 2.9959 - acc: 0.0485 - val_loss: 2.9963 - val_acc: 0.0475\n","Epoch 13/20\n","125/125 [==============================] - 33s 262ms/step - loss: 2.9959 - acc: 0.0494 - val_loss: 2.9963 - val_acc: 0.0470\n","Epoch 14/20\n","125/125 [==============================] - 34s 273ms/step - loss: 2.9959 - acc: 0.0458 - val_loss: 2.9963 - val_acc: 0.0470\n","Epoch 15/20\n","125/125 [==============================] - 33s 266ms/step - loss: 2.9959 - acc: 0.0504 - val_loss: 2.9963 - val_acc: 0.0470\n","Epoch 16/20\n","125/125 [==============================] - 34s 269ms/step - loss: 2.9959 - acc: 0.0489 - val_loss: 2.9963 - val_acc: 0.0470\n","Epoch 17/20\n","125/125 [==============================] - 32s 260ms/step - loss: 2.9959 - acc: 0.0489 - val_loss: 2.9963 - val_acc: 0.0470\n","Epoch 18/20\n","125/125 [==============================] - 34s 269ms/step - loss: 2.9958 - acc: 0.0503 - val_loss: 2.9963 - val_acc: 0.0470\n","Epoch 19/20\n","125/125 [==============================] - 34s 276ms/step - loss: 2.9959 - acc: 0.0484 - val_loss: 2.9963 - val_acc: 0.0475\n","Epoch 20/20\n","125/125 [==============================] - 37s 293ms/step - loss: 2.9958 - acc: 0.0470 - val_loss: 2.9963 - val_acc: 0.0475\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ff08addf710>"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":[],"metadata":{"id":"vt5JESlDuav0"}},{"cell_type":"code","source":["Export an end-to-end model\n","string_input = keras.Input(shape=(1,), dtype=\"string\")\n","x = vectorizer(string_input)\n","preds = model(x)\n","end_to_end_model = keras.Model(string_input, preds)\n","\n","probabilities = end_to_end_model.predict(\n","    [[\"this message is about computer graphics and 3D modeling\"]]\n",")\n","\n","class_names[np.argmax(probabilities[0])]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"dtXkNP4Bqd9L","executionInfo":{"status":"ok","timestamp":1669060304891,"user_tz":-60,"elapsed":508,"user":{"displayName":"Insafe MECHHEDAN","userId":"11716799724651238097"}},"outputId":"4c04899d-761e-489b-86f4-69b4abfd0e02"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 222ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["'comp.windows.x'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":27}]}]}