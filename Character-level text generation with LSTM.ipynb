{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b348591",
   "metadata": {},
   "source": [
    "### from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78fa3435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "import numpy as np\n",
    "import random\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e16ffee",
   "metadata": {},
   "source": [
    "### Prepare the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b4b7cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "600901/600901 [==============================] - 28s 47us/step\n",
      "Corpus length: 600893\n",
      "Total chars: 56\n",
      "Number of sequences: 200285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salma\\AppData\\Local\\Temp\\ipykernel_9824\\1178333198.py:24: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
      "C:\\Users\\salma\\AppData\\Local\\Temp\\ipykernel_9824\\1178333198.py:25: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "path = keras.utils.get_file(\n",
    "    \"nietzsche.txt\", origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\"\n",
    ")\n",
    "with io.open(path, encoding=\"utf-8\") as f:\n",
    "    text = f.read().lower()\n",
    "text = text.replace(\"\\n\", \" \")  # We remove newlines chars for nicer display\n",
    "print(\"Corpus length:\", len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print(\"Total chars:\", len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i : i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print(\"Number of sequences:\", len(sentences))\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a378f74",
   "metadata": {},
   "source": [
    "### Build the model: a single LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce1c90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(maxlen, len(chars))),\n",
    "        layers.LSTM(128),\n",
    "        layers.Dense(len(chars), activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f48fec",
   "metadata": {},
   "source": [
    "### Prepare the text sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6273b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1994bdd2",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f63ea7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1565/1565 [==============================] - 128s 80ms/step - loss: 1.9303\n",
      "\n",
      "Generating text after epoch: 0\n",
      "...Diversity: 0.2\n",
      "...Generating with seed: \"artially, not wholly.=--the specialized,\"\n",
      "...Generated:   and the propention and the infleection and the problem of the propention and and any in the deperions, and and and and well and the propentions and the procially and an and and and and in the propention and any the sentions and and and and and in the pressing in the presention of the pressions and and and the propentation and the into the in the processions of the individual to the stand the well\n",
      "\n",
      "...Diversity: 0.5\n",
      "...Generating with seed: \"artially, not wholly.=--the specialized,\"\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "batch_size = 128\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.fit(x, y, batch_size=batch_size, epochs=1)\n",
    "    print()\n",
    "    print(\"Generating text after epoch: %d\" % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print(\"...Diversity:\", diversity)\n",
    "\n",
    "        generated = \"\"\n",
    "        sentence = text[start_index : start_index + maxlen]\n",
    "        print('...Generating with seed: \"' + sentence + '\"')\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.0\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            sentence = sentence[1:] + next_char\n",
    "            generated += next_char\n",
    "\n",
    "        print(\"...Generated: \", generated)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700a27b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
